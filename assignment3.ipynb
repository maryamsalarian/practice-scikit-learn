{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment (III)"
      ],
      "metadata": {
        "id": "MCFdTvKhveyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "##Please write your full name/names and student IDs here:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Full Name:\n",
        "*   Student ID:"
      ],
      "metadata": {
        "id": "FH_OnG1VvWch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Question 1. (3 points)\n",
        "* **For this question, please follow the steps outlined below:**\n",
        "## Part (a):\n",
        "\n",
        "* **Data Loading:** Read the lymph dataset from your mounted Google Drive using Pandas.\n",
        "\n",
        "* **Data Splitting:** Split the dataset randomly into a 60% training set and a 40% test set using scikit-learn's train_test_split function.\n",
        "\n",
        "* **Handling Categorical Data:** Encode categorical attributes with one-hot encoding using pandas.get_dummies, dropping the first attribute to avoid redundancy.\n",
        "\n",
        "* **Decision Tree Classifier (1st Experiment):** Train a Decision Tree classifier in scikit-learn on the training data, setting the splitting criterion to \"entropy,\" and requiring a minimum of 4 samples to split an internal node. Keep other settings unchanged.\n",
        "\n",
        "* **Reproducibility:** Set the random_state to 32 in train_test_split and DecisionTreeClassifier to make your codes reproducible.\n",
        "\n",
        "* **Performance Evaluation (1st Experiment):** Report the Decision Tree classifier's accuracy on the test data. Also, generate a high-resolution tree visualization (use plt.figure(figsize=(12, 8), dpi=300)).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "awdwTnyJB5E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/EECS4412/data/lymph.csv\")  # Load your dataset"
      ],
      "metadata": {
        "id": "l0JAmO5G10VD",
        "outputId": "1b1b84d2-04e1-4b02-d7fc-d6560b790f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/data-mining-assignment3/datasets/lymph.csv\")  # Load your dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/EECS4412/data/lymph.csv\")  # Load your dataset\n",
        "\n",
        "#.............................................................................\n",
        "# write the rest here\n",
        "df = pd.DataFrame(data)\n",
        "# check the raw data\n",
        "print('first 5 rows:\\n', df.tail(5))\n",
        "# clean up the col name\n",
        "df.columns = df.columns.str.replace(\"'\", \"\").str.replace('\"', '').str.strip()\n",
        "print('\\nColumns:', df.columns)\n",
        "# split the data, 40% test, 60% train\n",
        "X=df.drop(\"class\", axis=1)\n",
        "y=df['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "# one-hot encoding\n",
        "# TODO: confirm col attrs\n",
        "encoded_df = pd.get_dummies(df, drop_first=True)\n",
        "print('\\nencoded_df:\\n', encoded_df.head(5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#.............................................................................\n"
      ],
      "metadata": {
        "id": "q5ZLZA2L9rHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c6eda4-1d54-4aef-d149-74a40602e2d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "first 5 rows:\n",
            "     'lymphatics' 'block_of_affere' 'bl_of_lymph_c' 'bl_of_lymph_s' 'by_pass'  \\\n",
            "143    displaced                no              no              no        no   \n",
            "144     deformed                no              no              no        no   \n",
            "145     deformed               yes              no              no       yes   \n",
            "146     deformed               yes              no              no        no   \n",
            "147       arched                no              no              no        no   \n",
            "\n",
            "    'extravasates' 'regeneration_of' 'early_uptake_in'  'lym_nodes_dimin'  \\\n",
            "143             no                no               yes                  1   \n",
            "144            yes                no               yes                  1   \n",
            "145            yes                no               yes                  1   \n",
            "146             no                no               yes                  1   \n",
            "147             no                no                no                  1   \n",
            "\n",
            "     'lym_nodes_enlar' 'changes_in_lym' 'defect_in_node' 'changes_in_node'  \\\n",
            "143                  3            round          lacunar           lacunar   \n",
            "144                  4            round      lac_central           lacunar   \n",
            "145                  2             oval      lac_central        lac_margin   \n",
            "146                  3             oval          lacunar       lac_central   \n",
            "147                  1             oval      lac_central        lac_margin   \n",
            "\n",
            "    'changes_in_stru' 'special_forms' 'dislocation_of' 'exclusion_of_no'  \\\n",
            "143            coarse        chalices              yes               yes   \n",
            "144            coarse        vesicles              yes               yes   \n",
            "145           diluted        chalices              yes               yes   \n",
            "146             faint        vesicles              yes               yes   \n",
            "147             faint        chalices              yes               yes   \n",
            "\n",
            "     'no_of_nodes_in'       'class'  \n",
            "143                 2    metastases  \n",
            "144                 6  malign_lymph  \n",
            "145                 4  malign_lymph  \n",
            "146                 3  malign_lymph  \n",
            "147                 2    metastases  \n",
            "\n",
            "Columns: Index(['lymphatics', 'block_of_affere', 'bl_of_lymph_c', 'bl_of_lymph_s',\n",
            "       'by_pass', 'extravasates', 'regeneration_of', 'early_uptake_in',\n",
            "       'lym_nodes_dimin', 'lym_nodes_enlar', 'changes_in_lym',\n",
            "       'defect_in_node', 'changes_in_node', 'changes_in_stru', 'special_forms',\n",
            "       'dislocation_of', 'exclusion_of_no', 'no_of_nodes_in', 'class'],\n",
            "      dtype='object')\n",
            "\n",
            "encoded_df:\n",
            "    lym_nodes_dimin  lym_nodes_enlar  no_of_nodes_in  lymphatics_deformed  \\\n",
            "0                1                4               5                False   \n",
            "1                1                3               3                False   \n",
            "2                3                1               7                 True   \n",
            "3                1                2               1                False   \n",
            "4                1                2               1                False   \n",
            "\n",
            "   lymphatics_displaced  lymphatics_normal  block_of_affere_yes  \\\n",
            "0                 False              False                 True   \n",
            "1                  True              False                 True   \n",
            "2                 False              False                False   \n",
            "3                 False              False                False   \n",
            "4                 False              False                False   \n",
            "\n",
            "   bl_of_lymph_c_yes  bl_of_lymph_s_yes  by_pass_yes  ...  changes_in_stru_no  \\\n",
            "0              False              False        False  ...               False   \n",
            "1              False              False         True  ...               False   \n",
            "2              False              False         True  ...               False   \n",
            "3              False              False        False  ...               False   \n",
            "4              False              False        False  ...               False   \n",
            "\n",
            "   changes_in_stru_reticular  changes_in_stru_stripped  special_forms_no  \\\n",
            "0                      False                      True             False   \n",
            "1                      False                     False             False   \n",
            "2                      False                     False             False   \n",
            "3                      False                     False             False   \n",
            "4                      False                     False             False   \n",
            "\n",
            "   special_forms_vesicles  dislocation_of_yes  exclusion_of_no_yes  \\\n",
            "0                    True                True                 True   \n",
            "1                    True                True                 True   \n",
            "2                    True               False                False   \n",
            "3                    True               False                 True   \n",
            "4                    True               False                False   \n",
            "\n",
            "   class_malign_lymph  class_metastases  class_normal  \n",
            "0                True             False         False  \n",
            "1                True             False         False  \n",
            "2               False             False         False  \n",
            "3                True             False         False  \n",
            "4               False              True         False  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part (b):\n",
        "\n",
        "\n",
        "Modify the minimum samples required for splitting to 32 and re-run the experiment. Report the accuracy of the Decision Tree classifier with the modified parameter and create a visualization of the tree. Discuss the differences between the two Decision Trees and their respective results, highlighting how changing the minimum samples for splitting affects the tree structure and performance.\n"
      ],
      "metadata": {
        "id": "XYVoumdcMaP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#.............................................................................\n",
        "# write the rest here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#............................................................................."
      ],
      "metadata": {
        "id": "WoSuBJPxMc6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Put your discussion here**\n",
        "\n",
        "\n",
        "Discuss here.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xWMoMrePY4Rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Question 2. (5 points)\n",
        "##Part (a):\n",
        "*  Write a Python function named \"preprocess\" that preprocesses and prepares\n",
        "datasets for machine learning. It must take a training dataset and an optional test dataset as input. The code must first identify categorical and numerical attributes, then handle missing values by imputing the mean for numerical attributes and the most frequent value for categorical attributes. It is worth noting that to determine if an attribute is numerical, the process should involve checking its data type and potentially examining the number of unique values. This is necessary because an attribute may appear to have an \"object\" data type but could, in fact, be numerical in nature.\n",
        "\n",
        "*  Subsequently, the \"preprocess\" code must standardize the numerical attributes by removing the mean and scaling to unit variance., and encodes categorical attributes using one-hot encoding.\n",
        "\n",
        "*  If a test dataset is provided, it must undergo the same preprocessing steps, ensuring that the imputation for missing values and data scaling are performed based on the values obtained from the training dataset, thus maintaining consistency between the two datasets.\n",
        "\n",
        "*  At the end, the function must return the preprocessed training and test datasets as (X_train, y_train, X_test, y_test) tuple if the test dataset exists. Otherwise it must return (X_train, y_train). X stands for independent processed attributes, while y indicates the class attribute."
      ],
      "metadata": {
        "id": "siG8VbMXIbmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "def preprocess(train_df, test_df=None):\n",
        "  #.............................................................................\n",
        "  # write your codes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #.............................................................................\n",
        "  if test_df is not None:\n",
        "      return X_train, y_train, X_test, y_test\n",
        "  else:\n",
        "      # If no test dataset is provided, return only the preprocessed training dataset\n",
        "      return X_train, y_train\n"
      ],
      "metadata": {
        "id": "eVfpNR8SHXel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part (b)\n",
        "In this task, your objective is to assess the performance of various machine learning classifiers for a credit classification problem. To ensure result reproducibility, set the random_state to 42 in KFold, Decision Tree, MLP Neural Network, and Random Forest. For the MLP, configure two hidden layers with 100 and 50 hidden units, respectively, and set max_iter to 1000. For the Random Forest, set the number of trees in the forest to 100. Finally, report the accuracy achieved on the test dataset."
      ],
      "metadata": {
        "id": "hrEuzGvzPCPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "\n",
        "# Load the training and test datasets\n",
        "credit_train = pd.read_csv(\"/content/drive/MyDrive/data-mining-assignment3/datasets/credit-a-train.csv\")\n",
        "credit_test = pd.read_csv(\"/content/drive/MyDrive/data-mining-assignment3/datasets/credit-a-test.csv\")\n",
        "\n",
        "# Preprocess the datasets and split them into features (X) and target (y)\n",
        "X_train, y_train, X_test, y_test = preprocess(credit_train, credit_test)\n",
        "  #.............................................................................\n",
        "  # write your codes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #............................................................................."
      ],
      "metadata": {
        "id": "FfasAsOYM3zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Put your discussion here**\n",
        "\n",
        "\n",
        "Discuss here.\n"
      ],
      "metadata": {
        "id": "jCssCXIfZ3OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Question 3. (4 points)\n",
        "## Part (a)\n",
        " Use the ionosphere dataset and Run a 10-fold cross validation to evaluate classification error rate of each algorithm. Use the preprocessing function you have written in question 2. Similar to the previous question, set the random_state to 42 in KFold, Decision Tree, MLP Neural Network, and Random Forest. For the MLP, configure two hidden layers with 100 and 50 hidden units, respectively, and set max_iter to 1000. For the Random Forest, set the number of trees in the forest to 100."
      ],
      "metadata": {
        "id": "HAU0pFK4PLDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Load the Ionosphere dataset and preprocess it\n",
        "ionosphere_dataset = pd.read_csv(\"/content/drive/MyDrive/data-mining-assignment3/datasets/ionosphere.csv\")\n",
        "X, y = preprocess(ionosphere_dataset)\n",
        "#.............................................................................\n",
        "# write your codes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#............................................................................."
      ],
      "metadata": {
        "id": "hk1EhL85QuBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part (b)\n",
        " Write a piece of code to perform feature selection using mutual information scores (mutual_info_classif in sklearn) on the processed ionosphere dataset (X) with its corresponding class labels (y). Your code must calculate these scores and then must select the top 5 attributes with the highest scores. Report what are these 5 selected attributes."
      ],
      "metadata": {
        "id": "KWq3AIU1Rt_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library for feature selection\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "#.............................................................................\n",
        "# write your codes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#............................................................................."
      ],
      "metadata": {
        "id": "b9xpcyvkSnOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part (c)\n",
        "Using only the top five attributes selected by the previous feature selection method, repeat k-fold validation to report the classification errors for each classifier. Then, discuss whether the results for each classifier have improved and explore the potential reasons behind any changes."
      ],
      "metadata": {
        "id": "qZY58i2xUI4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataset (X_low_dim) with only the selected attributes\n",
        "X_low_dim = X[selected_attrs]\n",
        "\n",
        "#.............................................................................\n",
        "# write your codes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#............................................................................."
      ],
      "metadata": {
        "id": "YSBbjsu2UPy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Put your discussion here**\n",
        "\n",
        "\n",
        "Discuss here.\n"
      ],
      "metadata": {
        "id": "BvFnVGhWaapb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " # Question 4. (4 points)\n",
        " Report the classification error rate on each data set and the average classification error rate of each method over all the data sets. Rank the methods according to their average classification error rate. For the top two methods (with the lowest average error rates), are their average error rates significantly different? Why? Comparing the method with the lowest average error rate and the one with the highest error rate, are their error rates significantly different? Why? Briefly discuss the results.\n",
        "\n",
        " (or result reproducibility, set the random_state to 42 in KFold, Decision Tree, MLP Neural Network, and Random Forest. Configure the MLP with two hidden layers having 100 and 50 hidden units, and set max_iter to 1000.)\n"
      ],
      "metadata": {
        "id": "XnM-sQmgWcSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#.............................................................................\n",
        "# write your codes here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#............................................................................."
      ],
      "metadata": {
        "id": "Xpb1SmryWgl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Put your discussion here**\n",
        "\n",
        "\n",
        "Discuss here.\n"
      ],
      "metadata": {
        "id": "IPoKqDTuachd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Question 5. (14 points)"
      ],
      "metadata": {
        "id": "7k7a5YplXIdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Please include your code for this section below. You may need to define various functions,\n",
        "#such as a preprocessing function, and incorporate them into your code.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQ5I8_5RajHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For question 5, your detailed report should be presented in a separate PDF file.**"
      ],
      "metadata": {
        "id": "DkVpfBdrdoXr"
      }
    }
  ]
}